{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Componentes Principales - Paso a Paso\n",
    "\n",
    "El ACP consiste esencialmente en identificar patrones y correlaciones entre variables para reducir la dimensionalidad de los datos solo cuando tenga sentido, de modo que retengamos la mayor cantidad de información posible.\n",
    "\n",
    "Se debe mencionar otra técnica conocida como el Análisis del Discriminante Lineal (ADL), que comporta, como su nombre indica, otra transformación lineal de los datos. Mientras que la ACP trata de buscar las Componentes Principales que maximizan la varianza del dato, el ADL intenta buscar direcciones que maximicen la separación (discriminación) entre las diferentes clases, lo cual puede ser muy útil cuando tengamos que aplicar algoritmos de clasificación de patrones.\n",
    "\n",
    "Mientras que le ACP ignora que haya columnas dedicadas a la clasificación, el LDA tiende a que todos los elementos que pertenecen a clases diferentes estén lo más separados posible, también con técnicas del álgebra lineal.\n",
    "\n",
    "Entonces, el ejercicio que realizaremos a continuación consistirá en reducir el espacio `m dimensional` original a un subespacio proyectado, un espacio `e dimensional` para reducir el coste computacional del algoritmo que apliquemos a posteriori.\n",
    "\n",
    "Implementaremos el análisis a mano, paso a paso, de modo que calcularemos los valores propios y cada uno de los vectores propios asociados a cada valor propio, que podrá ser interpretados como la magnitud del vector propio. Si se diera algún vector propio que tuviera una magnitud significativamente grande respecto al resto, lo que ocurrirá es que gran parte de la varianza se la llevará dicho valor, mientras que el resto retendrá menos información. De esta forma podremos ir determinando correctamente la separación.\n",
    "\n",
    "Habrá que tener en cuenta que los valores del data set se muevan en ordenes de magnitud diferentes.\n",
    "\n",
    "Teniendo todo ello en cuenta, el procedimiento será el siguiente.\n",
    "\n",
    "* Normalizar los datos para cada una de las `m` observaciones\n",
    "* Obtener los vectores y valores propios a partir de la matriz de covarianzas, de correlaciones o con la técnica de singular vector decomposition\n",
    "* Ordenar los valores propios en orden decreciente y quedarnos con los *p* que se correspondan con los *p* mayores y asi disminuir el número de variables del data set (`p < m`)\n",
    "* Construir la matriz de proyección `W` a partir de  los `p` vectores propios\n",
    "* Transformar el dataset original `X` a través de `W` para obtener así datos en el subespacio dimensional de dimensión *p*, que conformará `Y`.\n",
    "\n",
    "Utilizaremos nuevamente el data set de Iris para ejemplificar el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../GitHub/python-ml-course/datasets/iris/iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El data set de Iris no se eligió al azar. Este cuenta con una columna de clasificación de la especie. Esta columna deberá permanecer intacta tras la transformación lineal del dataset al aplicar el ACP.\n",
    "\n",
    "Por tanto, dividiremos el dataset en `X` e `y`, donde `X` estará compuesta por las variables a transformar y en `y` mantendremos las categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:4].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación de datos con Plotly\n",
    "\n",
    "Al aplicar la transformación a las variables (normalización) dejaremos de tener valores con sentido. Por tanto, antes de ello, realizaremos algunas representaciones de los datos de partida con el paquete `plotly`.\n",
    "\n",
    "Realizaremos un histograma con todas las variables contenidas dentro del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py\n",
    "import plotly.tools as tls\n",
    "\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.sign_in(username='carlosdavila91', api_key='sjP3SuTsus8qjId74CQx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlosdavila/anaconda3/lib/python3.7/site-packages/plotly/graph_objs/_deprecations.py:441: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.Marker is deprecated.\n",
      "Please replace it with one of the following more specific types\n",
      "  - plotly.graph_objs.scatter.Marker\n",
      "  - plotly.graph_objs.histogram.selected.Marker\n",
      "  - etc.\n",
      "\n",
      "\n",
      "/Users/carlosdavila/anaconda3/lib/python3.7/site-packages/plotly/graph_objs/_deprecations.py:40: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.Data is deprecated.\n",
      "Please replace it with a list or tuple of instances of the following types\n",
      "  - plotly.graph_objs.Scatter\n",
      "  - plotly.graph_objs.Bar\n",
      "  - plotly.graph_objs.Area\n",
      "  - plotly.graph_objs.Histogram\n",
      "  - etc.\n",
      "\n",
      "\n",
      "/Users/carlosdavila/anaconda3/lib/python3.7/site-packages/plotly/graph_objs/_deprecations.py:550: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.XAxis is deprecated.\n",
      "Please replace it with one of the following more specific types\n",
      "  - plotly.graph_objs.layout.XAxis\n",
      "  - plotly.graph_objs.layout.scene.XAxis\n",
      "\n",
      "\n",
      "/Users/carlosdavila/anaconda3/lib/python3.7/site-packages/plotly/graph_objs/_deprecations.py:578: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.YAxis is deprecated.\n",
      "Please replace it with one of the following more specific types\n",
      "  - plotly.graph_objs.layout.YAxis\n",
      "  - plotly.graph_objs.layout.scene.YAxis\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://plot.ly/~carlosdavila91/27.embed\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x11a49d550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces = []\n",
    "legend = {0:True,1:True,2:True,3:True}\n",
    "\n",
    "colors = {'setosa': 'rgb(255,127,20)',\n",
    "         'versicolor': 'rgb(31,220,120)',\n",
    "         'virginica': 'rgb(44,50,180)'}\n",
    "\n",
    "for col in range(4):\n",
    "    for key in colors:\n",
    "        traces.append(Histogram(x=X[y==key, col], opacity=0.7,\n",
    "                                xaxis='x%s'%(col+1), marker=Marker(color=colors[key]),\n",
    "                                name = key, showlegend = legend[col]))\n",
    "    legend = {0:False,1:False,2:False,3:False}\n",
    "    \n",
    "data = Data(traces)\n",
    "layout = Layout(barmode='overlay',\n",
    "                xaxis=XAxis(domain=[0,0.25],title=\"Long. Sépalos (cm)\"),\n",
    "                xaxis2=XAxis(domain=[0.3,0.5], title=\"Anch. Sépalos (cm)\"),\n",
    "                xaxis3=XAxis(domain=[0.55,0.75], title=\"Long. Pétalos (cm)\"),\n",
    "                xaxis4=XAxis(domain=[0.8,1.0], title=\"Anch. Pétalos (cm)\"),\n",
    "                yaxis=YAxis(title=\"Número de ejemplares\"),\n",
    "                title=\"Distribución de los rasgos de las diferentes flores Iris\")\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de los datos\n",
    "\n",
    "Para la normalización de los datos tomaremos el paquete `StandardScaler` de `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representamos los datos normalizados para comprobar que las distribuciones permanecen, en este caso, con los valores centrados en 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlosdavila/anaconda3/lib/python3.7/site-packages/plotly/graph_objs/_deprecations.py:441: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.Marker is deprecated.\n",
      "Please replace it with one of the following more specific types\n",
      "  - plotly.graph_objs.scatter.Marker\n",
      "  - plotly.graph_objs.histogram.selected.Marker\n",
      "  - etc.\n",
      "\n",
      "\n",
      "/Users/carlosdavila/anaconda3/lib/python3.7/site-packages/plotly/graph_objs/_deprecations.py:40: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.Data is deprecated.\n",
      "Please replace it with a list or tuple of instances of the following types\n",
      "  - plotly.graph_objs.Scatter\n",
      "  - plotly.graph_objs.Bar\n",
      "  - plotly.graph_objs.Area\n",
      "  - plotly.graph_objs.Histogram\n",
      "  - etc.\n",
      "\n",
      "\n",
      "/Users/carlosdavila/anaconda3/lib/python3.7/site-packages/plotly/graph_objs/_deprecations.py:550: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.XAxis is deprecated.\n",
      "Please replace it with one of the following more specific types\n",
      "  - plotly.graph_objs.layout.XAxis\n",
      "  - plotly.graph_objs.layout.scene.XAxis\n",
      "\n",
      "\n",
      "/Users/carlosdavila/anaconda3/lib/python3.7/site-packages/plotly/graph_objs/_deprecations.py:578: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.YAxis is deprecated.\n",
      "Please replace it with one of the following more specific types\n",
      "  - plotly.graph_objs.layout.YAxis\n",
      "  - plotly.graph_objs.layout.scene.YAxis\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://plot.ly/~carlosdavila91/29.embed\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a1cb1ad68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces = []\n",
    "legend = {0:True,1:True,2:True,3:True}\n",
    "\n",
    "colors = {'setosa': 'rgb(255,127,20)',\n",
    "         'versicolor': 'rgb(31,220,120)',\n",
    "         'virginica': 'rgb(44,50,180)'}\n",
    "\n",
    "for col in range(4):\n",
    "    for key in colors:\n",
    "        traces.append(Histogram(x=X_std[y==key, col], opacity=0.7,\n",
    "                                xaxis='x%s'%(col+1), marker=Marker(color=colors[key]),\n",
    "                                name = key, showlegend = legend[col]))\n",
    "    legend = {0:False,1:False,2:False,3:False}\n",
    "    \n",
    "data = Data(traces)\n",
    "layout = Layout(barmode='overlay',\n",
    "                xaxis=XAxis(domain=[0,0.25],title=\"Long. Sépalos (cm)\"),\n",
    "                xaxis2=XAxis(domain=[0.3,0.5], title=\"Anch. Sépalos (cm)\"),\n",
    "                xaxis3=XAxis(domain=[0.55,0.75], title=\"Long. Pétalos (cm)\"),\n",
    "                xaxis4=XAxis(domain=[0.8,1.0], title=\"Anch. Pétalos (cm)\"),\n",
    "                yaxis=YAxis(title=\"Número de ejemplares\"),\n",
    "                title=\"Distribución de los rasgos de las diferentes flores Iris\")\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Cálculo de la descomposición de valores y vectores propios\n",
    "\n",
    "#### a) Usando la matriz de covarianzas\n",
    "\n",
    "Este método es típico en el ámbito de las finanzas.\n",
    "\n",
    "Recordamos que los valores y vectores propios representan el núcleo fundamental de la ACP. A partir de la matriz de covarianzas o de correlaciones se extraen los vectores propios (componentes principales) que determinan las direcciones del nuevo espacio vectorial, mientras que los valores propios determinan la magnitud. En otras palabras, los valores propios determinan la varianza de los datos a través de los nuevos ejes.\n",
    "\n",
    "El enfoque más clásico del ACP lo que hace es llevar a cabo la descomposición de la matriz de covarianzas $\\Sigma$ de dimensiones `m x m`, donde cada elemento representa la covarianza entre dos de las características que se están analizando.\n",
    "\n",
    "La covarianza de dos rasgos cualesquiera se puede obtener a través de la siguiente fórmula.\n",
    "\n",
    "$\\sigma_{jk} = \\frac{1}{n-1}\\sum_{i=1}^m (x_{ij} - \\overline{x_j})(x_{ik} - \\overline{x_k})$\n",
    "\n",
    "Y esta fórmula se puede simplificar de la siguiente manera.\n",
    "\n",
    "$\\Sigma = \\frac{1}{n-1}((X-\\overline{x})^T(X-\\overline{x}))$\n",
    "\n",
    "Donde,\n",
    "\n",
    "$\\overline{x} = \\sum_{i=1}^n x_i \\in \\mathbb R^m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.73695157e-16, -7.81597009e-16, -4.26325641e-16, -4.73695157e-16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vect = np.mean(X_std, axis=0)\n",
    "mean_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La matriz de covarianzas es \n",
      "[[ 1.00671141 -0.11835884  0.87760447  0.82343066]\n",
      " [-0.11835884  1.00671141 -0.43131554 -0.36858315]\n",
      " [ 0.87760447 -0.43131554  1.00671141  0.96932762]\n",
      " [ 0.82343066 -0.36858315  0.96932762  1.00671141]]\n"
     ]
    }
   ],
   "source": [
    "cov_matrix = (X_std - mean_vect).T.dot((X_std-mean_vect))/(X_std.shape[0]-1)\n",
    "print(\"La matriz de covarianzas es \\n%s\"%cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos obtener la matriz de covarianzas directamente con `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00671141, -0.11835884,  0.87760447,  0.82343066],\n",
       "       [-0.11835884,  1.00671141, -0.43131554, -0.36858315],\n",
       "       [ 0.87760447, -0.43131554,  1.00671141,  0.96932762],\n",
       "       [ 0.82343066, -0.36858315,  0.96932762,  1.00671141]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(X_std.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver el sistema de ecuaciones, como habíamos comentado, habrá que obtener los valores y vectores propios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores propios \n",
      "[2.93808505 0.9201649  0.14774182 0.02085386]\n",
      "Vectores propios \n",
      "[[ 0.52106591 -0.37741762 -0.71956635  0.26128628]\n",
      " [-0.26934744 -0.92329566  0.24438178 -0.12350962]\n",
      " [ 0.5804131  -0.02449161  0.14212637 -0.80144925]\n",
      " [ 0.56485654 -0.06694199  0.63427274  0.52359713]]\n"
     ]
    }
   ],
   "source": [
    "eig_vals, eig_vect = np.linalg.eig(cov_matrix)\n",
    "print(\"Valores propios \\n%s\"%eig_vals)\n",
    "print(\"Vectores propios \\n%s\"%eig_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casualmente, los valores propios han aparecido ordenados.\n",
    "\n",
    "#### b) Usando la matriz de Correlaciones\n",
    "\n",
    "La matriz de Correlaciones no deja de ser más que la matriz de covarianzas que se obtiene cuando se han normalizado los datos. Por tanto, la descomposición de la matriz de covarianzas después de normalizar los datos es la misma que la descomposición de la matriz de correlaciones sin estandarizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.11756978,  0.87175378,  0.81794113],\n",
       "       [-0.11756978,  1.        , -0.4284401 , -0.36612593],\n",
       "       [ 0.87175378, -0.4284401 ,  1.        ,  0.96286543],\n",
       "       [ 0.81794113, -0.36612593,  0.96286543,  1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = np.corrcoef(X_std.T)\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores propios \n",
      "[2.91849782 0.91403047 0.14675688 0.02071484]\n",
      "Vectores propios \n",
      "[[ 0.52106591 -0.37741762 -0.71956635  0.26128628]\n",
      " [-0.26934744 -0.92329566  0.24438178 -0.12350962]\n",
      " [ 0.5804131  -0.02449161  0.14212637 -0.80144925]\n",
      " [ 0.56485654 -0.06694199  0.63427274  0.52359713]]\n"
     ]
    }
   ],
   "source": [
    "eig_vals_corr, eig_vect_corr = np.linalg.eig(corr_matrix)\n",
    "print(\"Valores propios \\n%s\"%eig_vals_corr)\n",
    "print(\"Vectores propios \\n%s\"%eig_vect_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Singular Value Decomposition\n",
    "\n",
    "Esta técnica es la que implementan sistemas sofisticados como las implementaciones en Python o R de la ACP, debido a a su eficacia computacional.\n",
    "\n",
    "El método nos devuelve los valores `u`, `s` y `v`, donde `u` es la misma matriz de vectores propios que en los casos anteirores. Sin embargo, el equivalente a los valores propios que obtuvimos anteioremente (`s`, en este caso) difiere bastante en rango de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52106591, -0.37741762,  0.71956635,  0.26128628],\n",
       "       [ 0.26934744, -0.92329566, -0.24438178, -0.12350962],\n",
       "       [-0.5804131 , -0.02449161, -0.14212637, -0.80144925],\n",
       "       [-0.56485654, -0.06694199, -0.63427274,  0.52359713]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u,s,v = np.linalg.svd(X_std.T)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.92306556, 11.7091661 ,  4.69185798,  1.76273239])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08239531e-01,  9.94577561e-02,  1.12996303e-01, ...,\n",
       "        -7.27030413e-02, -6.56112167e-02, -4.59137323e-02],\n",
       "       [-4.09957970e-02,  5.75731483e-02,  2.92000319e-02, ...,\n",
       "        -2.29793601e-02, -8.63643414e-02,  2.07800179e-03],\n",
       "       [ 2.72186462e-02,  5.00034005e-02, -9.42089147e-03, ...,\n",
       "        -3.84023516e-02, -1.98939364e-01, -1.12588405e-01],\n",
       "       ...,\n",
       "       [ 5.43380310e-02,  5.12936114e-03,  2.75184277e-02, ...,\n",
       "         9.89532683e-01, -1.41206665e-02, -8.30595907e-04],\n",
       "       [ 1.96438400e-03,  8.48544595e-02,  1.78604309e-01, ...,\n",
       "        -1.25488246e-02,  9.52049996e-01, -2.19201906e-02],\n",
       "       [ 2.46978090e-03,  5.83496936e-03,  1.49419118e-01, ...,\n",
       "        -7.17729676e-04, -2.32048811e-02,  9.77300244e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Las componentes principales\n",
    "\n",
    "Recordamos que el objetivo de la ACP es la disminución de la dimnesionalidad del espacio vectorial inicial meidante la proyección de los datos en subespacios de dimensión más pequeña desde las direcciones que definen los vectores propios desde los ejes.\n",
    "\n",
    "Además, los vectores propios deberán tener dimensión 1 para que se trate de una base de un espacio vectorial. Comprobamos esto en primer lugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La longitud del VP es:  0.9999999999999997\n",
      "La longitud del VP es:  1.0000000000000002\n",
      "La longitud del VP es:  1.0\n",
      "La longitud del VP es:  0.9999999999999997\n"
     ]
    }
   ],
   "source": [
    "for ev in eig_vect:\n",
    "    print(\"La longitud del VP es: \", np.linalg.norm(ev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la comprobación podemos decir que lo que tenemos es una base de un espacio vectorial original que nos va a servir para llevar a cabo el cálculo de las componentes principales.\n",
    "\n",
    "Para construir un espacio vectorial de dimensionalidad inferior vamos a buscar cada uno de los valores propios. Los vectores propios que tengan los valores propios menores de la distribución de los datos serán los que vamos a eliminar. Para ello construiremos un ranking con los valores propios para luego elegir el top de ellos que más nos interese (el que represente la mayor parte de la variabilidad de los datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.938085050199993,\n",
       "  array([ 0.52106591, -0.26934744,  0.5804131 ,  0.56485654])),\n",
       " (0.9201649041624873,\n",
       "  array([-0.37741762, -0.92329566, -0.02449161, -0.06694199])),\n",
       " (0.1477418210449481,\n",
       "  array([-0.71956635,  0.24438178,  0.14212637,  0.63427274])),\n",
       " (0.020853862176462803,\n",
       "  array([ 0.26128628, -0.12350962, -0.80144925,  0.52359713]))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigen_pairs = [(np.abs(eig_vals[i]), eig_vect[:,i]) for i in range(len(eig_vals))]\n",
    "eigen_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La lista de valores y vectores propios ya viene ordenada. Si no ocurriera esto, el método para ordenar la lista sería el siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.938085050199993,\n",
       "  array([ 0.52106591, -0.26934744,  0.5804131 ,  0.56485654])),\n",
       " (0.9201649041624873,\n",
       "  array([-0.37741762, -0.92329566, -0.02449161, -0.06694199])),\n",
       " (0.1477418210449481,\n",
       "  array([-0.71956635,  0.24438178,  0.14212637,  0.63427274])),\n",
       " (0.020853862176462803,\n",
       "  array([ 0.26128628, -0.12350962, -0.80144925,  0.52359713]))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigen_pairs.sort()\n",
    "eigen_pairs.reverse()\n",
    "eigen_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores propios en orden descendente:\n",
      "2.938085050199993\n",
      "0.9201649041624873\n",
      "0.1477418210449481\n",
      "0.020853862176462803\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores propios en orden descendente:\")\n",
    "for ep in eigen_pairs:\n",
    "    print(ep[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos que determinar cuanta varianza explica cada rasgo. Para ello, utilizaremos la técnica de la varianza explicativa.\n",
    "\n",
    "Para ello, representaremos un gráfico acumulativo para representar la varianza de cada una de las componentes principales y determinar las que serán necesarias en nuestro dataset final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum = sum(eig_vals)\n",
    "var_exp = [(i/total_sum)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprovecharemos la librería `plotly` para hacer la representación combinada de los valores de la varianza explicada en diagrama de barras por un lado, y por el otro, un scatter plot con los puntos unidos por líneas del valor acumulado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://plot.ly/~carlosdavila91/31.embed\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a1d60cfd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot1 = Bar(x=[\"CP %s\"%i for i in range(1,5)], y=var_exp, showlegend=False)\n",
    "plot2 = Scatter(x=[\"CP %s\"%i for i in range(1,5)], y=cum_var_exp, showlegend=True, \n",
    "                name = \"% de Varianza Explicada Acumulada\")\n",
    "\n",
    "data = Data([plot1,plot2])\n",
    "\n",
    "layout = Layout(xaxis = XAxis(title=\"Componentes principales\"),\n",
    "               yaxis = YAxis(title=\"% de Varianza\"),\n",
    "               title = \"Porcentaje de variabilidad explicada por cada componente principal\")\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico podemos observar que tomando las dos primeras componentes podemos explicar un 95,8% de la información, por lo que podríamos eliminar las componentes 3 y 4 sin perder información relevante.\n",
    "\n",
    "Con ello, pasaremos a la construcción de la matriz de proyección, que será la que nos sirva para transformar el dataset original al nuevo subespacio vectorial de rasgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52106591, -0.37741762],\n",
       "       [-0.26934744, -0.92329566],\n",
       "       [ 0.5804131 , -0.02449161],\n",
       "       [ 0.56485654, -0.06694199]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.hstack((eigen_pairs[0][1].reshape(4,1),\n",
    "               eigen_pairs[1][1].reshape(4,1)))\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Proyectar las variables en el nuevo subespacio vectorial\n",
    "\n",
    "La proyección la llevaremos a cabo a través de la siguiente expresión\n",
    "\n",
    "$Y = X \\cdot W, X \\in M(\\mathbb R)_{150,4}, W \\in M(\\mathbb R)_{4,2}, Y \\in (\\mathbb R)_{150,2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X_std.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://plot.ly/~carlosdavila91/39.embed\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x11a310cf8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name in {'setosa','versicolor','virginica'}:\n",
    "    result = Scatter(x=Y[y==name,0], y=Y[y==name, 1],\n",
    "                     mode='markers', name=name, \n",
    "                     marker=Marker(size=12, line=Line(color='rgba(220,220,220,0.15)',\n",
    "                                                     width=0.5),\n",
    "                                  opacity=0.8))\n",
    "    results.append(result)\n",
    "    \n",
    "data=Data(results)\n",
    "layout=Layout(showlegend=True, scene=Scene(xaxis=XAxis(title=\"Componenete Principal 1\"),\n",
    "                                          yaxis=YAxis(title=\"Componente Principal 2\")))\n",
    "\n",
    "fig=Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
